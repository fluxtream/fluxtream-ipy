{
 "metadata": {
  "name": "",
  "signature": "sha256:3a5159841ad9e99e31b7e660322c95a24bfd0fe9457e95a0a598cad2d9fbe1aa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re, requests, StringIO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load Fluxtream library and authenticate\n",
      "---------------------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def exec_ipynb(url):\n",
      "    import json, re, urllib2\n",
      "    nb = (urllib2.urlopen(url) if re.match(r'https?:', url) else open(url)).read()\n",
      "    exec '\\n'.join([''.join(cell['input']) for cell in json.loads(nb)['worksheets'][0]['cells'] if cell['cell_type'] == 'code']) in globals()\n",
      "\n",
      "exec_ipynb('Fluxtream-Library.ipynb')\n",
      "fluxtream_login()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Download CSV from Google Spreadsheet\n",
      "------------------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "device_name = 'Smells_1'\n",
      "spreadsheet_key = '16YI2PPXCWgqC0RL8LcAFlHqcnHoaVuo_5n4EHrUFmVI'\n",
      "timezone = tz.gettz('America/Chicago')\n",
      "\n",
      "csv_download_url = 'https://docs.google.com/spreadsheet/ccc?key=%s&output=csv' % spreadsheet_key\n",
      "print 'Downloading CSV from %s...' % csv_download_url\n",
      "# Google requires cookies to work across 30x redirects, so we use 'requests' library\n",
      "data = requests.get(csv_download_url).content\n",
      "print '%d lines downloaded' % len(data.split('\\n'))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Execute this cell to define the functions for reading in CSV files.\n",
      "\n",
      "# Keep track of where you save the files, and enter in the next section\n",
      "import httplib, urllib, time, base64, string, datetime, json, csv, calendar,pprint\n",
      "from dateutil import tz\n",
      "from dateutil import parser\n",
      "\n",
      "def epoch_time(dt):\n",
      "    epoch = datetime.datetime(1970, 1, 1, tzinfo=tz.tzutc())\n",
      "    return (dt - epoch).total_seconds()    \n",
      "\n",
      "#------------------------------------------------------------------------------------------------------------------\n",
      "#\n",
      "# The timezone argument should be a python timezone object.  These are typically created \n",
      "# using some variant of the tz.gettz() function.  Documentation is here:\n",
      "#   http://niemeyer.net/python-dateutil#head-b79630fbbda87af6d6d121737510fd7ea5aeea97\n",
      "# Examples include:\n",
      "#    tz.gettz()  uses the local timezone this computer is currently set to\n",
      "#    tz.gettz(\"America/New_York\")  uses US Eastern time, with appropriate adjustments for daylight savings time\n",
      "#    tz.gettz(\"America/Los_Angeles\")  uses US Pacific time, with appropriate adjustments for DST\n",
      "#    tz.gettz(\"EST\")  uses US Eastern Standard Time, which (I think) would ignore DST and always be UTC-5\n",
      "# The list of available timezones is at: http://en.wikipedia.org/wiki/List_of_tz_database_time_zones\n",
      "\n",
      "# To instead use a known hour offset from UTC, you could instead use something like this to create the timzeone arg:\n",
      "#    tz.tzoffset(None, gmt_hr_offset * 3600)\n",
      "# where gmt_hr_offset is a numeric number of hours different from UTC.  \n",
      "#\n",
      "# West of Greenwich England gmt_hr_offset values are negative numbers: \n",
      "#     EST would be gmt_hr_offset = -5, EDT would be gmt_hr_offset = -4\n",
      "# East of Greenwich gmt_hr_offset values are positive numbers:\n",
      "#     Mainland Europe in the summer would be gmt_hr_offset=2, and in the winter would be gmt_hr_offset=1.\n",
      "\n",
      "# Replace non alnum chars with _\n",
      "def sanitize_channel_name(name):\n",
      "    return re.sub(r'\\W+', '_', name).strip('_')\n",
      "\n",
      "def epoch_time(dt):\n",
      "    epoch = datetime.datetime(1970, 1, 1, tzinfo=tz.tzutc())\n",
      "    return (dt - epoch).total_seconds()    \n",
      "\n",
      "def parse_google_sheet_csv(csv_as_string, timezone):\n",
      "    csv_reader = csv.reader(StringIO.StringIO(csv_as_string), delimiter=',')\n",
      "\n",
      "    # First row is header, with names of columns\n",
      "    header = csv_reader.next()\n",
      "    \n",
      "    # First column is assumed to be timestamp;  skip it\n",
      "    column_names = [sanitize_channel_name(channel) for channel in header[1:]]\n",
      "    \n",
      "    # Data, in Fluxtream format\n",
      "    parsed_data = []\n",
      "    \n",
      "    # Read the data\n",
      "    for row in csv_reader:\n",
      "        datetime_str = row.pop(0)\n",
      "        if (datetime_str != ''):\n",
      "            # Google Docs's time format is month/date/year 24-hr time in localtime.  See\n",
      "            #   http://www.tutorialspoint.com/python/time_strptime.htm\n",
      "            # for details of how the parsing for that works in python\n",
      "            local_ts = datetime.datetime.strptime(datetime_str, '%m/%d/%Y %H:%M:%S')\n",
      "            local_ts = local_ts.replace(tzinfo=timezone)\n",
      "            parsed_row = [epoch_time(local_ts)]\n",
      "\n",
      "            # Iterate over the colums.  At each column, if the cell is not empty, add a row\n",
      "            for sample in row:\n",
      "                if sample == '':\n",
      "                    parsed_sample = None\n",
      "                elif sample.isdigit():\n",
      "                    parsed_sample = float(sample)\n",
      "                else:\n",
      "                    parsed_sample = sample\n",
      "                parsed_row.append(parsed_sample)\n",
      "            parsed_data.append(parsed_row)\n",
      "        \n",
      "    return (column_names, parsed_data)\n",
      "\n",
      "(column_names, records) = parse_google_sheet_csv(data, timezone)\n",
      "fluxtream_upload(device_name, column_names, records)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}